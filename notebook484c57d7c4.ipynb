{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-01T18:10:22.331911Z",
     "iopub.status.busy": "2021-09-01T18:10:22.331472Z",
     "iopub.status.idle": "2021-09-01T18:10:25.268472Z",
     "shell.execute_reply": "2021-09-01T18:10:25.266997Z",
     "shell.execute_reply.started": "2021-09-01T18:10:22.33182Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sc\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('max_columns', 300)\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# for tree binarisation\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# to build the models\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T18:10:25.270526Z",
     "iopub.status.busy": "2021-09-01T18:10:25.270148Z",
     "iopub.status.idle": "2021-09-01T18:10:34.722816Z",
     "shell.execute_reply": "2021-09-01T18:10:34.721751Z",
     "shell.execute_reply.started": "2021-09-01T18:10:25.270491Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/beyond-analysis/train.csv')\n",
    "test = pd.read_csv('../input/beyond-analysis/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T18:10:34.724911Z",
     "iopub.status.busy": "2021-09-01T18:10:34.724443Z",
     "iopub.status.idle": "2021-09-01T18:10:34.731419Z",
     "shell.execute_reply": "2021-09-01T18:10:34.730393Z",
     "shell.execute_reply.started": "2021-09-01T18:10:34.724878Z"
    }
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T18:10:34.733514Z",
     "iopub.status.busy": "2021-09-01T18:10:34.733149Z",
     "iopub.status.idle": "2021-09-01T18:10:35.600117Z",
     "shell.execute_reply": "2021-09-01T18:10:35.59899Z",
     "shell.execute_reply.started": "2021-09-01T18:10:34.733479Z"
    }
   },
   "outputs": [],
   "source": [
    "y = train['CATEGORY_1'].unique()\n",
    "y1 = test['CATEGORY_1'].unique()\n",
    "a = []\n",
    "for i in y:\n",
    "    a.append(i)\n",
    "for i in y1:\n",
    "    a.append(i)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(a)\n",
    "train['cat1'] = encoder.transform(train['CATEGORY_1'])\n",
    "test['cat1'] = encoder.transform(test['CATEGORY_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T18:10:35.601898Z",
     "iopub.status.busy": "2021-09-01T18:10:35.601517Z",
     "iopub.status.idle": "2021-09-01T18:10:36.455669Z",
     "shell.execute_reply": "2021-09-01T18:10:36.45437Z",
     "shell.execute_reply.started": "2021-09-01T18:10:35.601866Z"
    }
   },
   "outputs": [],
   "source": [
    "y = train['CATEGORY_2'].unique()\n",
    "y1 = test['CATEGORY_2'].unique()\n",
    "a = []\n",
    "for i in y:\n",
    "    a.append(i)\n",
    "for i in y1:\n",
    "    a.append(i)\n",
    "encoder1 = LabelEncoder()\n",
    "encoder1.fit(a)\n",
    "train['cat2'] = encoder1.transform(train['CATEGORY_2'])\n",
    "test['cat2'] = encoder1.transform(test['CATEGORY_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T18:10:36.457373Z",
     "iopub.status.busy": "2021-09-01T18:10:36.457031Z",
     "iopub.status.idle": "2021-09-01T18:10:36.703705Z",
     "shell.execute_reply": "2021-09-01T18:10:36.702643Z",
     "shell.execute_reply.started": "2021-09-01T18:10:36.457339Z"
    }
   },
   "outputs": [],
   "source": [
    "train.drop(['CATEGORY_1', 'CATEGORY_2'], axis=1, inplace=True)\n",
    "test.drop(['CATEGORY_1', 'CATEGORY_2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T18:10:36.705508Z",
     "iopub.status.busy": "2021-09-01T18:10:36.705134Z",
     "iopub.status.idle": "2021-09-01T18:10:36.710181Z",
     "shell.execute_reply": "2021-09-01T18:10:36.709323Z",
     "shell.execute_reply.started": "2021-09-01T18:10:36.705472Z"
    }
   },
   "outputs": [],
   "source": [
    "a = {}\n",
    "for i in train.columns:\n",
    "    if(i=='UNIQUE_IDENTIFIER'):\n",
    "        continue\n",
    "    a[str(i)] = 'mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T18:10:36.712805Z",
     "iopub.status.busy": "2021-09-01T18:10:36.712345Z",
     "iopub.status.idle": "2021-09-01T18:10:36.729602Z",
     "shell.execute_reply": "2021-09-01T18:10:36.727954Z",
     "shell.execute_reply.started": "2021-09-01T18:10:36.71277Z"
    }
   },
   "outputs": [],
   "source": [
    "a1 = {}\n",
    "for i in test.columns:\n",
    "    if(i=='UNIQUE_IDENTIFIER'):\n",
    "        continue\n",
    "    a1[str(i)] = 'mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T18:10:36.731642Z",
     "iopub.status.busy": "2021-09-01T18:10:36.731227Z",
     "iopub.status.idle": "2021-09-01T18:10:37.18091Z",
     "shell.execute_reply": "2021-09-01T18:10:37.179471Z",
     "shell.execute_reply.started": "2021-09-01T18:10:36.731605Z"
    }
   },
   "outputs": [],
   "source": [
    "aggregation_functions = a\n",
    "train1 = train.groupby(train['UNIQUE_IDENTIFIER'], as_index=False).aggregate(aggregation_functions)\n",
    "aggregation_functions = a1\n",
    "test1 = test.groupby(test['UNIQUE_IDENTIFIER'], as_index=False).aggregate(aggregation_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T18:10:37.184098Z",
     "iopub.status.busy": "2021-09-01T18:10:37.183597Z",
     "iopub.status.idle": "2021-09-01T18:10:37.224935Z",
     "shell.execute_reply": "2021-09-01T18:10:37.223454Z",
     "shell.execute_reply.started": "2021-09-01T18:10:37.184048Z"
    }
   },
   "outputs": [],
   "source": [
    "train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T18:10:37.226777Z",
     "iopub.status.busy": "2021-09-01T18:10:37.226424Z",
     "iopub.status.idle": "2021-09-01T18:10:37.357495Z",
     "shell.execute_reply": "2021-09-01T18:10:37.356551Z",
     "shell.execute_reply.started": "2021-09-01T18:10:37.22674Z"
    }
   },
   "outputs": [],
   "source": [
    "train2 = train.drop(['Y1', 'Y2', 'cat1', 'cat2', 'DEPOSIT_2', 'DEPOSIT_TRAILS'], axis=1)\n",
    "test2 = test.drop(['cat1', 'cat2', 'DEPOSIT_2', 'DEPOSIT_TRAILS'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T18:10:37.358995Z",
     "iopub.status.busy": "2021-09-01T18:10:37.358576Z",
     "iopub.status.idle": "2021-09-01T18:10:37.362444Z",
     "shell.execute_reply": "2021-09-01T18:10:37.361691Z",
     "shell.execute_reply.started": "2021-09-01T18:10:37.358965Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T18:10:37.364015Z",
     "iopub.status.busy": "2021-09-01T18:10:37.363582Z",
     "iopub.status.idle": "2021-09-01T18:10:37.380089Z",
     "shell.execute_reply": "2021-09-01T18:10:37.37909Z",
     "shell.execute_reply.started": "2021-09-01T18:10:37.363979Z"
    }
   },
   "outputs": [],
   "source": [
    "def b(a):\n",
    "    return np.quantile(a, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T18:10:37.382032Z",
     "iopub.status.busy": "2021-09-01T18:10:37.381476Z",
     "iopub.status.idle": "2021-09-01T18:10:37.395325Z",
     "shell.execute_reply": "2021-09-01T18:10:37.394491Z",
     "shell.execute_reply.started": "2021-09-01T18:10:37.381995Z"
    }
   },
   "outputs": [],
   "source": [
    "def b1(a):\n",
    "    return np.quantile(a, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T18:10:39.681112Z",
     "iopub.status.busy": "2021-09-01T18:10:39.680532Z",
     "iopub.status.idle": "2021-09-01T18:25:24.115713Z",
     "shell.execute_reply": "2021-09-01T18:25:24.114427Z",
     "shell.execute_reply.started": "2021-09-01T18:10:39.681066Z"
    }
   },
   "outputs": [],
   "source": [
    "a = {}\n",
    "for i in train2.columns:\n",
    "    if(i=='UNIQUE_IDENTIFIER'):\n",
    "        continue\n",
    "    if(i=='SEQUENCE_NO'):\n",
    "        a[str(i)] = [np.mean, np.max]\n",
    "    else:\n",
    "        a[str(i)] = [np.mean, np.max, np.min, np.std, np.median, b, b1]\n",
    "aggregation_functions = a\n",
    "df_train = train2.groupby(train2['UNIQUE_IDENTIFIER'], as_index=False).agg(aggregation_functions)\n",
    "aggregation_functions = a\n",
    "df_test = test2.groupby(test2['UNIQUE_IDENTIFIER'], as_index=False).agg(aggregation_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T18:26:58.354759Z",
     "iopub.status.busy": "2021-09-01T18:26:58.354358Z",
     "iopub.status.idle": "2021-09-01T18:26:58.518684Z",
     "shell.execute_reply": "2021-09-01T18:26:58.517751Z",
     "shell.execute_reply.started": "2021-09-01T18:26:58.354726Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T18:27:00.100561Z",
     "iopub.status.busy": "2021-09-01T18:27:00.099844Z",
     "iopub.status.idle": "2021-09-01T18:27:00.116825Z",
     "shell.execute_reply": "2021-09-01T18:27:00.115382Z",
     "shell.execute_reply.started": "2021-09-01T18:27:00.100493Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['cat1'] = train1['cat1']\n",
    "df_test['cat1'] = test1['cat1']\n",
    "df_train['cat2'] = train1['cat2']\n",
    "df_test['cat2'] = test1['cat2']\n",
    "df_train['Y1'] = train1['Y1']\n",
    "df_train['Y2'] = train1['Y2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T18:27:00.701645Z",
     "iopub.status.busy": "2021-09-01T18:27:00.701117Z",
     "iopub.status.idle": "2021-09-01T18:27:00.860606Z",
     "shell.execute_reply": "2021-09-01T18:27:00.859678Z",
     "shell.execute_reply.started": "2021-09-01T18:27:00.701606Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T18:27:01.2362Z",
     "iopub.status.busy": "2021-09-01T18:27:01.235681Z",
     "iopub.status.idle": "2021-09-01T18:27:01.244192Z",
     "shell.execute_reply": "2021-09-01T18:27:01.242906Z",
     "shell.execute_reply.started": "2021-09-01T18:27:01.236167Z"
    }
   },
   "outputs": [],
   "source": [
    "target_cols = ['Y1', 'Y2']\n",
    "feature_cols = [col for col in df_train.columns if col not in [('Y2', ''), ('UNIQUE_IDENTIFIER', ''), ('Y1', '')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T18:27:02.872009Z",
     "iopub.status.busy": "2021-09-01T18:27:02.871626Z",
     "iopub.status.idle": "2021-09-01T18:43:54.249296Z",
     "shell.execute_reply": "2021-09-01T18:43:54.248178Z",
     "shell.execute_reply.started": "2021-09-01T18:27:02.871979Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(train, test):\n",
    "    # Hyperparammeters (optimized)\n",
    "    seed = 1111\n",
    "    params = {\n",
    "        'learning_rate': 0.001,        \n",
    "        'lambda_l1': 2,\n",
    "        'lambda_l2': 2,\n",
    "        'num_leaves': 750,\n",
    "        'min_sum_hessian_in_leaf': 20,\n",
    "        'feature_fraction': 0.8,\n",
    "        'feature_fraction_bynode': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 42,\n",
    "        'min_data_in_leaf': 100,\n",
    "        'max_depth': 6,\n",
    "        'seed': seed,\n",
    "        'feature_fraction_seed': seed,\n",
    "        'bagging_seed': seed,\n",
    "        'drop_seed': seed,\n",
    "        'data_random_seed': seed,\n",
    "        'objective': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs': -1,\n",
    "    }     \n",
    "    \n",
    "    # Split features and target\n",
    "    x = train[feature_cols]\n",
    "    y = train['Y2']\n",
    "    x_test = test[feature_cols]\n",
    "    x = x.values\n",
    "    x_test = x_test.values\n",
    "    \n",
    "    # Create out of folds array\n",
    "    oof_predictions = np.zeros(x.shape[0])\n",
    "    # Create test array to store predictions\n",
    "    test_predictions = np.zeros(x_test.shape[0])\n",
    "    # Create a KFold object\n",
    "    kfold = KFold(n_splits = 5, random_state = 66, shuffle = True)\n",
    "    # Iterate through each fold\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(x)):\n",
    "        print(f'Training fold {fold + 1}')\n",
    "        x_train, x_val = x[trn_ind], x[val_ind]\n",
    "        y_train, y_val = y[trn_ind], y[val_ind]\n",
    "        train_dataset = lgb.Dataset(x_train, y_train)\n",
    "        val_dataset = lgb.Dataset(x_val, y_val)\n",
    "        model = lgb.train(params = params, \n",
    "                          train_set = train_dataset, \n",
    "                          valid_sets = [train_dataset, val_dataset], \n",
    "                          num_boost_round = 10000, early_stopping_rounds = 1000, \n",
    "                          verbose_eval = 100)\n",
    "#         model = lgb.LGBMRegressor(n_estimators=10000, random_state=47,learning_rate=0.005,importance_type = 'gain',\n",
    "#                      n_jobs = -1,metric='rmse')\n",
    "#         model.fit(x_train,y_train,eval_set = [(x_train,y_train),(x_val,y_val)],early_stopping_rounds=500,verbose=50)\n",
    "        plt.figure(figsize=(12,6))\n",
    "        lgb.plot_importance(model, max_num_features=20)\n",
    "        plt.title(\"Feature importance\")\n",
    "        plt.show()\n",
    "        # Add predictions to the out of folds array\n",
    "        oof_predictions[val_ind] = model.predict(x_val)\n",
    "        # Predict the test set\n",
    "        test_predictions += model.predict(x_test) / 5\n",
    "        \n",
    "    rmspe_score = sqrt(mean_squared_error(y, oof_predictions))\n",
    "    print(f'Our out of folds RMSPE is {rmspe_score}')\n",
    "    # Return test predictions\n",
    "    return test_predictions\n",
    "\n",
    "# Traing and evaluate\n",
    "test_predictions1 = train_and_evaluate(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T18:44:41.265289Z",
     "iopub.status.busy": "2021-09-01T18:44:41.264848Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(train, test):\n",
    "    # Hyperparammeters (optimized)\n",
    "    seed = 1111\n",
    "    params = {\n",
    "        'learning_rate': 0.001,        \n",
    "        'lambda_l1': 1,\n",
    "        'lambda_l2': 2,\n",
    "        'num_leaves': 256,\n",
    "        'min_sum_hessian_in_leaf': 20,\n",
    "        'feature_fraction': 0.8,\n",
    "        'feature_fraction_bynode': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 42,\n",
    "        'min_data_in_leaf': 100,\n",
    "        'max_depth': 7,\n",
    "        'seed': seed,\n",
    "        'feature_fraction_seed': seed,\n",
    "        'bagging_seed': seed,\n",
    "        'drop_seed': seed,\n",
    "        'data_random_seed': seed,\n",
    "        'objective': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs': -1,\n",
    "    }     \n",
    "    \n",
    "    # Split features and target\n",
    "    x = train[feature_cols]\n",
    "    y = train['Y1']\n",
    "    x_test = test[feature_cols]\n",
    "    x = x.values\n",
    "    x_test = x_test.values\n",
    "    \n",
    "    # Create out of folds array\n",
    "    oof_predictions = np.zeros(x.shape[0])\n",
    "    # Create test array to store predictions\n",
    "    test_predictions = np.zeros(x_test.shape[0])\n",
    "    # Create a KFold object\n",
    "    kfold = KFold(n_splits = 5, random_state = 66, shuffle = True)\n",
    "    # Iterate through each fold\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(x)):\n",
    "        print(f'Training fold {fold + 1}')\n",
    "        x_train, x_val = x[trn_ind], x[val_ind]\n",
    "        y_train, y_val = y[trn_ind], y[val_ind]\n",
    "        train_dataset = lgb.Dataset(x_train, y_train)\n",
    "        val_dataset = lgb.Dataset(x_val, y_val)\n",
    "        model = lgb.train(params = params, \n",
    "                          train_set = train_dataset, \n",
    "                          valid_sets = [train_dataset, val_dataset], \n",
    "                          num_boost_round = 30000, early_stopping_rounds = 1000, \n",
    "                          verbose_eval = 100)\n",
    "#         model = lgb.LGBMRegressor(n_estimators=10000, random_state=47,learning_rate=0.005,importance_type = 'gain',\n",
    "#                      n_jobs = -1,metric='rmse')\n",
    "#         model.fit(x_train,y_train,eval_set = [(x_train,y_train),(x_val,y_val)],early_stopping_rounds=500,verbose=50)\n",
    "        plt.figure(figsize=(12,6))\n",
    "        lgb.plot_importance(model, max_num_features=20)\n",
    "        plt.title(\"Feature importance\")\n",
    "        plt.show()\n",
    "        # Add predictions to the out of folds array\n",
    "        oof_predictions[val_ind] = model.predict(x_val)\n",
    "        # Predict the test set\n",
    "        test_predictions += model.predict(x_test) / 5\n",
    "        \n",
    "    rmspe_score = sqrt(mean_squared_error(y, oof_predictions))\n",
    "    print(f'Our out of folds RMSPE is {rmspe_score}')\n",
    "    # Return test predictions\n",
    "    return test_predictions\n",
    "\n",
    "# Traing and evaluate\n",
    "test_predictions = train_and_evaluate(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T17:40:13.633746Z",
     "iopub.status.busy": "2021-09-01T17:40:13.633333Z",
     "iopub.status.idle": "2021-09-01T17:40:13.638855Z",
     "shell.execute_reply": "2021-09-01T17:40:13.637683Z",
     "shell.execute_reply.started": "2021-09-01T17:40:13.633709Z"
    }
   },
   "outputs": [],
   "source": [
    "target_cols = ['Y1', 'Y2']\n",
    "feature_cols1 = [col for col in train1.columns if col not in ['Y2', 'UNIQUE_IDENTIFIER', 'Y1', 'DEPOSIT_2', 'DEPOSIT_TRAILS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T17:40:15.777324Z",
     "iopub.status.busy": "2021-09-01T17:40:15.77679Z",
     "iopub.status.idle": "2021-09-01T17:41:40.950742Z",
     "shell.execute_reply": "2021-09-01T17:41:40.9497Z",
     "shell.execute_reply.started": "2021-09-01T17:40:15.777281Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(train, test):\n",
    "    # Split features and target\n",
    "    x = train[feature_cols1]\n",
    "    y = train['Y1']\n",
    "    x_test = test[feature_cols1]\n",
    "    \n",
    "    # Create out of folds array\n",
    "    oof_predictions = np.zeros(x.shape[0])\n",
    "    # Create test array to store predictions\n",
    "    test_predictions = np.zeros(x_test.shape[0])\n",
    "    # Create a KFold object\n",
    "    kfold = KFold(n_splits = 5, random_state = 66, shuffle = True)\n",
    "    # Iterate through each fold\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(x)):\n",
    "        print(f'Training fold {fold + 1}')\n",
    "        x_train, x_val = x.iloc[trn_ind], x.iloc[val_ind]\n",
    "        y_train, y_val = y.iloc[trn_ind], y.iloc[val_ind]\n",
    "        model = MLPRegressor(hidden_layer_sizes=(32,32), max_iter=2000, learning_rate='adaptive', early_stopping=True, activation='tanh', verbose=True, random_state=1)\n",
    "        model.fit(x_train, y_train)\n",
    "        # Add predictions to the out of folds array\n",
    "        oof_predictions[val_ind] = model.predict(x_val)\n",
    "        # Predict the test set\n",
    "        test_predictions += model.predict(x_test) / 5\n",
    "        \n",
    "    rmspe_score = sqrt(mean_squared_error(y, oof_predictions))\n",
    "    print(f'Our out of folds RMSPE is {rmspe_score}')\n",
    "    # Return test predictions\n",
    "    return test_predictions\n",
    "\n",
    "# Traing and evaluate\n",
    "preds1 = train_and_evaluate(train1, test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T17:41:40.953511Z",
     "iopub.status.busy": "2021-09-01T17:41:40.952768Z",
     "iopub.status.idle": "2021-09-01T17:50:41.657949Z",
     "shell.execute_reply": "2021-09-01T17:50:41.656769Z",
     "shell.execute_reply.started": "2021-09-01T17:41:40.953459Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(train, test):\n",
    "    # Split features and target\n",
    "    x = train[feature_cols]\n",
    "    y = train['Y2']\n",
    "    x.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    x.fillna(x.mean(), inplace=True)\n",
    "    x_test = test[feature_cols]\n",
    "    x_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    x_test.fillna(x_test.mean(), inplace=True)\n",
    "    x = x.values\n",
    "    x_test = x_test.values\n",
    "    \n",
    "    # Create out of folds array\n",
    "    oof_predictions = np.zeros(x.shape[0])\n",
    "    # Create test array to store predictions\n",
    "    test_predictions = np.zeros(x_test.shape[0])\n",
    "    # Create a KFold object\n",
    "    kfold = KFold(n_splits = 5, random_state = 66, shuffle = True)\n",
    "    # Iterate through each fold\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(x)):\n",
    "        print(f'Training fold {fold + 1}')\n",
    "        x_train, x_val = x[trn_ind], x[val_ind]\n",
    "        y_train, y_val = y[trn_ind], y[val_ind]\n",
    "        model = MLPRegressor(hidden_layer_sizes=(24,24,16), max_iter=2000, learning_rate='adaptive', early_stopping=True, activation='logistic', verbose=True, random_state=1)\n",
    "        model.fit(x_train, y_train)\n",
    "        pred = model.predict(x_train)\n",
    "        print('rf train rmse: {}'.format(sqrt(mean_squared_error(y_train, pred))))\n",
    "        pred = model.predict(x_val)\n",
    "        print('rf test rmse: {}'.format(sqrt(mean_squared_error(y_val, pred))))\n",
    "        # Add predictions to the out of folds array\n",
    "        oof_predictions[val_ind] = model.predict(x_val)\n",
    "        # Predict the test set\n",
    "        test_predictions += model.predict(x_test) / 5\n",
    "        \n",
    "    rmspe_score = sqrt(mean_squared_error(y, oof_predictions))\n",
    "    print(f'Our out of folds RMSPE is {rmspe_score}')\n",
    "    # Return test predictions\n",
    "    return test_predictions\n",
    "\n",
    "# Traing and evaluate\n",
    "preds2 = train_and_evaluate(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T18:04:23.998458Z",
     "iopub.status.busy": "2021-09-01T18:04:23.997983Z",
     "iopub.status.idle": "2021-09-01T18:04:24.004304Z",
     "shell.execute_reply": "2021-09-01T18:04:24.003322Z",
     "shell.execute_reply.started": "2021-09-01T18:04:23.998426Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'UNIQUE_IDENTIFIER': test1['UNIQUE_IDENTIFIER'], \n",
    "                   'Y1': test_predictions*0.8+0.2*preds1, 'Y2': test_predictions1*0.83+0.17*preds2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T18:04:27.322564Z",
     "iopub.status.busy": "2021-09-01T18:04:27.321999Z",
     "iopub.status.idle": "2021-09-01T18:04:27.570623Z",
     "shell.execute_reply": "2021-09-01T18:04:27.569918Z",
     "shell.execute_reply.started": "2021-09-01T18:04:27.322529Z"
    }
   },
   "outputs": [],
   "source": [
    "sub.to_csv('sub8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
